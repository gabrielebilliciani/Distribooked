{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531fd30c-8d57-479a-8217-ff7b78e3c9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset restructuring process...\n",
      "\n",
      "Loading enriched dataset...\n",
      "Successfully loaded 100866 records from the enriched dataset\n",
      "\n",
      "Restructuring dataset...\n",
      "Successfully restructured 100866 records\n",
      "\n",
      "Saving restructured dataset...\n",
      "Successfully saved restructured dataset to final_dataset.json\n",
      "\n",
      "Dataset restructuring complete!\n",
      "Original record count: 100866\n",
      "Restructured record count: 100866\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def load_enriched_dataset(filepath: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load the enriched dataset from JSON file.\n",
    "    \n",
    "    This function reads our previously enriched dataset that contains both the\n",
    "    nested and flat author information. It includes error handling and validation\n",
    "    to ensure we can properly process the data.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the enriched dataset JSON file\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing the dataset records\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"Successfully loaded {len(data)} records from the enriched dataset\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading enriched dataset: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def restructure_record(record: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Restructure a single record to have the desired format.\n",
    "    \n",
    "    This function reorganizes the fields in each record to ensure that all\n",
    "    author-related information is properly nested within the 'authors' field.\n",
    "    It also removes duplicate author information from the top level.\n",
    "    \n",
    "    Args:\n",
    "        record: Dictionary containing a single record's data\n",
    "    \n",
    "    Returns:\n",
    "        Restructured record dictionary\n",
    "    \"\"\"\n",
    "    # Create a new record with the desired structure\n",
    "    restructured = {\n",
    "        # Copy all fields except author-related ones\n",
    "        \"title\": record[\"title\"],\n",
    "        \"subtitle\": record[\"subtitle\"],\n",
    "        \"issued\": record[\"issued\"],\n",
    "        \"publisher\": record[\"publisher\"],\n",
    "        \"language\": record[\"language\"],\n",
    "        \"categories\": record[\"categories\"],\n",
    "        \"ISBN 10\": record[\"ISBN 10\"],\n",
    "        \"ISBN 13\": record[\"ISBN 13\"],\n",
    "        \"main_image_url\": record[\"main_image_url\"]\n",
    "    }\n",
    "    \n",
    "    # Handle the authors field - ensure it's always a list of dictionaries\n",
    "    authors = record.get(\"authors\", [])\n",
    "    if authors and isinstance(authors, list):\n",
    "        # Update the first author's information with the enriched data\n",
    "        if len(authors) > 0:\n",
    "            # Keep existing author information\n",
    "            author_info = authors[0].copy()\n",
    "            # Add the enriched information\n",
    "            if record.get(\"author_avatar\"):\n",
    "                author_info[\"author_avatar\"] = record[\"author_avatar\"]\n",
    "            if record.get(\"author_about\"):\n",
    "                author_info[\"author_about\"] = record[\"author_about\"]\n",
    "            # Update the authors list with the enriched information\n",
    "            authors[0] = author_info\n",
    "    \n",
    "    # Add the updated authors list to the restructured record\n",
    "    restructured[\"authors\"] = authors\n",
    "    \n",
    "    return restructured\n",
    "\n",
    "def clean_dataset(data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Clean and restructure the entire dataset.\n",
    "    \n",
    "    This function processes all records in the dataset, ensuring consistent\n",
    "    structure and proper nesting of author information. It also handles any\n",
    "    edge cases or inconsistencies in the data.\n",
    "    \n",
    "    Args:\n",
    "        data: List of dictionaries containing all records\n",
    "    \n",
    "    Returns:\n",
    "        List of restructured record dictionaries\n",
    "    \"\"\"\n",
    "    cleaned_data = []\n",
    "    for record in data:\n",
    "        cleaned_record = restructure_record(record)\n",
    "        cleaned_data.append(cleaned_record)\n",
    "    \n",
    "    print(f\"Successfully restructured {len(cleaned_data)} records\")\n",
    "    return cleaned_data\n",
    "\n",
    "def save_dataset(data: List[Dict[str, Any]], output_path: str):\n",
    "    \"\"\"\n",
    "    Save the restructured dataset to a JSON file.\n",
    "    \n",
    "    This function saves the cleaned and restructured data with proper formatting\n",
    "    and indentation for readability.\n",
    "    \n",
    "    Args:\n",
    "        data: List of dictionaries containing the restructured records\n",
    "        output_path: Path where the cleaned dataset should be saved\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "        print(f\"Successfully saved restructured dataset to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving dataset: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def main(input_path: str, output_path: str):\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the dataset restructuring process.\n",
    "    \n",
    "    This function coordinates the loading, restructuring, and saving of the\n",
    "    dataset, providing feedback about the process at each step.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to the enriched dataset JSON file\n",
    "        output_path: Path where the restructured dataset should be saved\n",
    "    \"\"\"\n",
    "    print(\"Starting dataset restructuring process...\")\n",
    "    \n",
    "    # Load the enriched dataset\n",
    "    print(\"\\nLoading enriched dataset...\")\n",
    "    data = load_enriched_dataset(input_path)\n",
    "    \n",
    "    # Clean and restructure the data\n",
    "    print(\"\\nRestructuring dataset...\")\n",
    "    cleaned_data = clean_dataset(data)\n",
    "    \n",
    "    # Save the restructured dataset\n",
    "    print(\"\\nSaving restructured dataset...\")\n",
    "    save_dataset(cleaned_data, output_path)\n",
    "    \n",
    "    print(\"\\nDataset restructuring complete!\")\n",
    "    print(f\"Original record count: {len(data)}\")\n",
    "    print(f\"Restructured record count: {len(cleaned_data)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\n",
    "        input_path=\"enriched_dataset.json\",\n",
    "        output_path=\"final_dataset.json\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411648d8-3b16-4117-aefe-fbba309d8da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
